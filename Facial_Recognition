import face_recognition
import cv2
import os
import numpy as np

# Load known faces
KNOWN_FACE_DIR = "faces"
known_encodings = []
known_names = []

print("Loading known faces...")
for name in os.listdir(KNOWN_FACE_DIR):
    person_dir = os.path.join(KNOWN_FACE_DIR, name)
    for filename in os.listdir(person_dir):
        image_path = os.path.join(person_dir, filename)
        image = face_recognition.load_image_file(image_path)
        encodings = face_recognition.face_encodings(image)

        if encodings:
            known_encodings.append(encodings[0])
            known_names.append(name)

# Initialize camera
cap = cv2.VideoCapture(0)  # 0 = default USB camera

print("Starting camera... Press 'q' to exit.")
while True:
    ret, frame = cap.read()
    if not ret:
        continue

    # Resize for faster processing
    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
    rgb_small = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)

    face_locations = face_recognition.face_locations(rgb_small)
    face_encodings = face_recognition.face_encodings(rgb_small, face_locations)

    for encoding, location in zip(face_encodings, face_locations):
        matches = face_recognition.compare_faces(known_encodings, encoding)
        face_distances = face_recognition.face_distance(known_encodings, encoding)
        best_match_index = np.argmin(face_distances)

        name = "Unknown"
        if matches[best_match_index]:
            name = known_names[best_match_index]

        # Draw results on screen
        top, right, bottom, left = [v * 4 for v in location]  # scale back up
        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
        cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)

        print(f"Detected: {name}")

    cv2.imshow("Face ID", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
